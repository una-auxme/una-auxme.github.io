---
lang: de
img_src: assets\boborzi\diffusion.png
title: Anpassung vonDiffusion Modelle
tags: ["pm", "ma"]
date: 2024-09-11
---
Du findest generative Modelle wie Stable Diffusion oder DALL-E, die anhand von Text detailreiche Bilder erzeugen können, spannend und hast Interesse, dich in aktuelle Machine-Learning-Themen einzuarbeiten?

In dieser Arbeit hast du die Möglichkeit, Methoden wie [Stable Diffusion](https://github.com/CompVis/stable-diffusion) und [SV3D](https://stability.ai/news/introducing-stable-video-3d) genauer kennenzulernen. Stable Diffusion ermöglicht es, Bilder anhand von Text oder anderen Vorgaben zu erzeugen. Bei der Methode SV3D wird ein Bild als Vorgabe verwendet, um mehrere Bilder zu generieren, die das Objekt aus verschiedenen Perspektiven zeigen. Mithilfe dieser Perspektiven können anschließend 3D-Objekte erzeugt werden. In der Arbeit sollen Möglichkeiten untersucht werden, wie Diffsuion Modelle auf andere Eingaben, wie zum Beispiel Zeichnungen, konditioniert werden können und wie sich diese Eingaben auf die Generierung auswirken. Abhängig von der Art der Arbeit können verschiedene Ansätze untersucht werden.
