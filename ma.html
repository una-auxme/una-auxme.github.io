<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Lehrstuhl für Mechatronik - AuxMe</title>
<meta name="description" content="Hier findet ihr aktuelle Themen für studentische Arbeiten an unserem Lehrstuhl.">



<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="AuxMe">
<meta property="og:title" content="Lehrstuhl für Mechatronik">
<meta property="og:url" content="https://una-auxme.github.io/ma">


  <meta property="og:description" content="Hier findet ihr aktuelle Themen für studentische Arbeiten an unserem Lehrstuhl.">



  <meta property="og:image" content="https://una-auxme.github.io/assets/logo/AuxMe.jpg">










<link rel="canonical" href="https://una-auxme.github.io/ma">












<!-- end _includes/seo.html -->


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="shortcut icon" type="image/png" href="/assets/logo/logo.png">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="/assets/logo/logo.png" alt="Lehrstuhl für Mechatronik"></a>
        
        <a class="site-title" href="/">
          Lehrstuhl für Mechatronik
          
        </a>
          <a class="btn btn--primary" href="/">Abschluss- & Forschungsarbeiten</a>
        
            
            <a class="btn btn--primary masthead__robocup-btn" href="/robocup/">RoboCup@Home</a>
          
        
        <ul class="visible-links"></ul>
        <div class="lang-switcher">
          
    
    

    
        
            <a href="/en">English</a>
        
    

        </div>        
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      
  







<div class="page__hero--overlay"
  style="background-color: #000; background-image: linear-gradient(rgba(0, 0, 0, 0.5), rgba(0, 0, 0, 0.5)), url('/assets/logo/AuxMe.jpg');"
>
  
    <div class="wrapper">
      <h1 id="page-title" class="page__title" itemprop="headline">
        
          Lehrstuhl für Mechatronik

        
      </h1>
      
        <p class="page__lead">Hier findet ihr aktuelle Themen für studentische Arbeiten an unserem Lehrstuhl.
</p>
      
      


      
        <p>
        
          <a href="https://www.uni-augsburg.de/de/fakultaet/fai/informatik/prof/imech/" class="btn btn--light-outline btn--large">Zum Lehrstuhl</a>
        
        </p>
      
    </div>
  
  
    <span class="page__hero-caption">Photo credit: <strong>Peter Krönes</strong>
</span>
  
</div>







<div id="main" role="main">
  


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Lehrstuhl für Mechatronik">
    <meta itemprop="description" content="Hier findet ihr aktuelle Themen für studentische Arbeiten an unserem Lehrstuhl.">
    
    

    <div class="page__inner-wrap">
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> Themen</h4></header>
              <ul class="toc__menu"><li><a href="#differenzierbarkeit-von-nachbarschaftssuche-und-der-earth-movers-distance">Differenzierbarkeit von Nachbarschaftssuche und der Earth Mover’s Distance</a></li><li><a href="#weiterentwicklung-der-methodik-von-graph-neural-networks">Weiterentwicklung der Methodik von Graph Neural Networks</a></li><li><a href="#reharobotik-für-armfunktionstraining-nach-schlaganfall">Reharobotik für Armfunktionstraining nach Schlaganfall</a></li><li><a href="#klassifikation-von-griffvariaten-für-roboterhände">Klassifikation von Griffvariaten für Roboterhände</a></li><li><a href="#vorhersage-von-leistungsfähigkeit-von-menschen-durch-gpt-modelle">Vorhersage von Leistungsfähigkeit von Menschen durch GPT Modelle</a></li><li><a href="#datengetriebene-model-predictive-control">Datengetriebene Model Predictive Control</a></li><li><a href="#weiterentwicklung-unserer-softwarepakete-für-graph-neural-networks">Weiterentwicklung unserer Softwarepakete für Graph Neural Networks</a></li><li><a href="#datengetriebene-beobachter">Datengetriebene Beobachter</a></li><li><a href="#fine-tuning-von-large-reconstruction-models-für-die-3d-objektgenerierung">Fine-tuning von Large Reconstruction Models für die 3D Objektgenerierung</a></li><li><a href="#konditionierung-von-diffusion-modellen">Konditionierung von Diffusion Modellen</a></li></ul>
            </nav>
          </aside>
        
        <p>Wir freuen uns sehr über die Zusammenarbeit mit den Studenten und wir möchten euch kurz vorstellen, in welchen Themengebieten wir uns besonders über eure Unterstützung freuen würden. Kommt gerne mit euren Ideen und Vorstellungen vorbei und wir suchen gemeinsam nach Möglichkeiten, wie ihr eure Abschlussarbeiten, Seminararbeiten, Forschungs- und Projektmodule bei uns erledigen könnt. Für Fragen stehen wir euch jederzeit zur Verfügung.</p>

<div class="filter">
  <h3>Filter:</h3>
  <p>
    
      <a class="btn btn--light-outline" href="/sb">Seminararbeit Bachelor</a>
    
    
    <a class="btn btn--light-outline" href="/sm">Seminararbeit Master</a>
    
  </p>
  <p>
    
    <a class="btn btn--light-outline" href="/fm">Forschungsmodul</a>
    
    
    <a class="btn btn--light-outline" href="/pm">Projektmodul</a>
    
  </p>
  <p>
    
    <a class="btn btn--light-outline" href="/ba">Bachelorarbeit</a>
    
    
      <a class="btn btn--success" href="/ma">Masterarbeit</a>
    
  </p>
  <p>
    
    <a class="btn btn--light-outline" href="/hiwi">Hiwi-Stelle</a>
    
  </p>
  <p>
    <a class="btn btn--primary" href="/">Filter zurücksetzen</a>
  </p>
</div>

<h3 id="differenzierbarkeit-von-nachbarschaftssuche-und-der-earth-movers-distance">Differenzierbarkeit von Nachbarschaftssuche und der Earth Mover’s Distance</h3>

<div class="feature__wrapper">
  <div class="feature__item--left">
    <div class="archive__item">
      <div class="archive__item-teaser">
        
          <div style="position:relative">
            <img src="assets\kircher\Showroom_1.png" />
            <span class="archive__item-caption">© Universität Augsburg</span>
          </div>
        
        
        <h4>Tags:</h4>
        <ul>
          
            
            
            
            
              <li>Projektmodul</li>
            
            
            
            
          
            
            
            
            
            
            
              <li>Masterarbeit</li>
            
            
          
            
            
            
              <li>Forschungsmodul</li>
            
            
            
            
            
          
            
            
            
            
            
              <li>Bachelorarbeit</li>
            
            
            
          
        </ul>
        
        <a class="btn btn--primary" href="https://www.uni-augsburg.de/de/fakultaet/fai/informatik/prof/imech/team/josef-kircher">Kontakt</a>
        
      </div>
      <div class="archive__item-body">
        <p>Im Kontext von Deep Learning und Neuronalen Netzen ist für den Trainingsprozess unerlässlich, dass der Code vollständig differenzierbar ist, um die Gradienten für die Trainingsupdates berechnen zu können. Bei zwei Teilen ist dies aktuell noch nicht so.</p>

        <p>In vorhergegangen studentischen Arbeiten wurde eine GPU-fähige Nachbarschaftssuche und eine Lossfunktion basierend auf der Earth Mover’s Distance implementiert. Diese sind in der aktuellen Form nicht differenzierbar.</p>

        <p>Das Ziel der Arbeit ist die Untersuchung, ob einerseits eine differenzierbare Implementierung anhand der bestehenden Modul möglich ist, oder ob andererseits in der Literatur passendere Algorithmen verfügbar sind, die es dann zu implementieren gilt.</p>

        <p>Vorgehen:</p>
        <ul>
  <li>Einarbeitung in die Nachbarsschaftssuche und Earth Mover’s Distance</li>
  <li>Überprüfung der Anwendbarkeit von AD und Literaturrecherche</li>
  <li>Implementierung und Testung</li>
</ul>

        <p>Vorraussetzungen:</p>
        <ul>
  <li>Vorkenntnisse in Julia sind wünschenswert</li>
  <li>Erfahrungen mit NeuralODE und AD sind von großem Vorteil</li>
</ul>
      </div>
    </div>
  </div>
</div>

<h3 id="weiterentwicklung-der-methodik-von-graph-neural-networks">Weiterentwicklung der Methodik von Graph Neural Networks</h3>

<div class="feature__wrapper">
  <div class="feature__item--left">
    <div class="archive__item">
      <div class="archive__item-teaser">
        
        
        <h4>Tags:</h4>
        <ul>
          
            
            
            
            
              <li>Projektmodul</li>
            
            
            
            
          
            
            
            
            
            
              <li>Bachelorarbeit</li>
            
            
            
          
            
            
            
            
            
            
              <li>Masterarbeit</li>
            
            
          
            
            
            
            
            
            
            
              <li>Hiwi-Stelle</li>
            
          
        </ul>
        
        <a class="btn btn--primary" href="https://www.uni-augsburg.de/de/fakultaet/fai/informatik/prof/imech/team/julian-trommer">Kontakt</a>
        
          <a class="btn btn--primary" href="https://github.com/una-auxme/MeshGraphNets.jl">Zusätzliche Informationen</a>
        
      </div>
      <div class="archive__item-body">
        <p>Graph Neural Networks (GNNs) eignen sich hervorragend als Surrogatmodelle für graphbasierte Simulationen, denen komplexe physikalische Phänomene zugrunde liegen. Durch das Lernen lokaler Zusammenhänge können sie auch bei sich ändernden Geometrien oder Topologien des Graphen weiterverwendet werden, ohne dass ein erneutes Training erforderlich ist. In dieser Arbeit soll die Methodik des in unserem <a href="https://github.com/una-auxme/MeshGraphNets.jl">Softwarepaket</a> bestehenden GNN-Ansatzes weiterentwickelt werden, um ein schnelleres Training und eine höhere Vorhersagegenauigkeit zu ermöglichen.</p>

        <p>Mögliche Schwerpunkte sind die Evaluation der Modellperformance bei variierenden Geometrien, die Untersuchung verschiedener Trainingsstrategien sowie die Integration zusätzlichen physikalischen Wissens.</p>

        <p>Die Arbeit richtet sich an Studierende mit Interesse an maschinellem Lernen, der Programmiersprache <a href="https://julialang.org/">Julia</a> (oder Python, da viele Parallelen existieren) und aktueller Forschung im Bereich Scientific Machine Learning (SciML).</p>
      </div>
    </div>
  </div>
</div>

<h3 id="reharobotik-für-armfunktionstraining-nach-schlaganfall">Reharobotik für Armfunktionstraining nach Schlaganfall</h3>

<div class="feature__wrapper">
  <div class="feature__item--left">
    <div class="archive__item">
      <div class="archive__item-teaser">
        
          <div style="position:relative">
            <img src="assets\mandischer\rehabot.png" />
            <span class="archive__item-caption">© Universität Augsburg</span>
          </div>
        
        
        <h4>Tags:</h4>
        <ul>
          
            
            
            
            
            
            
              <li>Masterarbeit</li>
            
            
          
        </ul>
        
        <a class="btn btn--primary" href="https://www.uni-augsburg.de/de/fakultaet/fai/informatik/prof/imech/team/nils-mandischer">Kontakt</a>
        
      </div>
      <div class="archive__item-body">
        <p>Gemeinsam mit dem Therapiezentrum Burgau wollen wir zeitnah mit der Entwicklung eines Reharoboters starten, der zur teilautomatisierten Therapie im Armfunktionstraining nach Schlaganfall eingesetzt werden soll. Der Roboter verstärkt und führt dabei die Bewegung der Patientinnen und Patienten mit Armparese (min. halbseitige Lähmung der oberen Extremitäten) und entlastet dadurch die Therapeutinnen und Therapeuten.</p>

        <p><em>Thema 1</em></p>

        <p>Für Medizinsysteme ist Sicherheit von höchster Bedeutung. Insbesondere bei Lähmungen sind technische Fehler in der Roboterbewegung fatal, da die Patientinnen und Patienten im Zweifel keinen Schmerz verspüren und äußern können. Dadurch besteht ein hohes Verletzungsrisiko. Darüber sind Patientinnen und Patienten häufig mit einer Spastik (schmerzhafte Verkrampfung von Muskeln) konfrontiert. Arbeitet der Roboter gegen den Widerstand der Verkrampfung kann dies zu starken Schmerzen führen.</p>

        <p>In der Arbeit ist ein Sicherheitslayer zu implementieren, der die grundlegende Sicherheit gegen mechanische Verletzungen sicherstellt. Insbesondere soll eine Spastikerkennung implementiert werden, die eine Verkrampfung von einem aktiven Gegendruck und einer Lähmung unterscheiden kann. Dazu wird die Kraftsensorik des Tool-Flansch des Universal Robots UR10e und der daran angeschlossenen anthropomorphen Hand verwendet.</p>

        <p><em>Thema 2</em></p>

        <p>Der Reharoboter soll nicht nur autark mit den Patientinnen und Patienten arbeiten, sondern auch gemeinsam mit den Therapeutinnen und Therapeuten eine Therapieübung durchführen. Dadurch entsteht ein ternäres System, in dem Therapeutin, Patient und Roboter gemeinsam den Arm des Patienten kontrollieren. Ternäre Systeme sind im sogenannten Shared Control (grob: gemeinsame Regelung von technischen Systemen) nur selten vertreten. Darüber hinaus stellt ein teilgelähmter Arm kein steifes Element im System dar und unterliegt Sicherheitskriterien (s.o.).</p>

        <p>In der Arbeit soll untersucht werden, welche Ansätze aus dem Shared Control sich eignen, das System unter Führung des menschlichen Therapeuten zu regeln. Denkbar sind bspw. Spiele (Spieltheorie), um die Interaktion zu beschreiben. Als Ausgangspunkt dient die am Prüfstand vorhandene Sensorik (Kraft/Momente, Kameras, Motion Capture) und der Universal Robots UR10e sowie vorhandene Methoden zur Schwerelosregelung.</p>

        <p><em>Was wir bieten</em></p>
        <ul>
  <li>Einblicke in die Mensch-Roboter-Interaktion und Rehamedizin</li>
  <li>Lockere Arbeitsathmosphäre</li>
  <li>Flexible Betreuung</li>
  <li>Arbeiten am realen Roboter</li>
</ul>

        <p><em>Was du mitbringst</em></p>
        <ul>
  <li>Studium der Ingenieursinformatik, Medizininformatik, Informatik, oder ähnliche</li>
  <li>Interesse an Mensch-Roboter-Interaktion mit medizinischem Einschlag</li>
  <li>Vorwissen in Robotik und ROS 2 wünschenswert</li>
</ul>
      </div>
    </div>
  </div>
</div>

<h3 id="klassifikation-von-griffvariaten-für-roboterhände">Klassifikation von Griffvariaten für Roboterhände</h3>

<div class="feature__wrapper">
  <div class="feature__item--left">
    <div class="archive__item">
      <div class="archive__item-teaser">
        
          <div style="position:relative">
            <img src="assets\mandischer\mia_hand.jpg" />
            <span class="archive__item-caption">© Universität Augsburg</span>
          </div>
        
        
        <h4>Tags:</h4>
        <ul>
          
            
            
            
            
              <li>Projektmodul</li>
            
            
            
            
          
            
            
            
            
            
              <li>Bachelorarbeit</li>
            
            
            
          
            
            
            
            
            
            
              <li>Masterarbeit</li>
            
            
          
        </ul>
        
        <a class="btn btn--primary" href="https://www.uni-augsburg.de/de/fakultaet/fai/informatik/prof/imech/team/nils-mandischer">Kontakt</a>
        
      </div>
      <div class="archive__item-body">
        <p>Am Lehrstuhl für Mechatronik untersuchen wir Mensch-Roboter Interaktion in verschiedenen Anwendungsfällen. Dabei werden Roboterbewegungen per Learning from Demonstration (d.h. durch Nachahmung des Menschen durch den Roboter) angelernt. Einen zunehmend wichtigen Faktor spielen dabei für den Menschen ausgelegte Prozesse, sei es das Schraubeneindrehen in der Arbeitswelt oder Lebensmittel einräumen im Haushalt. Entsprechend gewinnen roboterhände zunehmend an Relevanz.</p>

        <p>In dieser Arbeit sollen menschliche Bewegungen per markerless Tracking wahrgenommen werden (dazu existieren Vorarbeiten) und basierend auf dem Skelett der Hand, die vorliegenden Griffvarianten klassifiziert werden. Unsere Roboterhand (Prensilia Mia Hand) verfügt über vordefinierte Griffvarianten (z.B. Pinzetten- oder Umfassungsgriffe). Diese sollen anschließend auf die menschliche Bewegung gematched werden. Das ergebnis der Arbeit dient dann als Eingang in unsere Ansätz für das Learning from Demonstration.</p>

        <p><em>Deine Aufgaben</em></p>
        <ul>
  <li>Erstellen eines kleinen Datensatzes verschiedener Griffvarianten mit unserem Prüfstand</li>
  <li>Vergleich und Auswahl von geeigneten Machine Learning Verfahren für die Klassifikation</li>
  <li>Validierung der Klassifikation auf dem erstellten Datensatz</li>
</ul>

        <p><em>Du bietest</em></p>
        <ul>
  <li>Studium der Ingenieursinformatik, Informatik, Medizininformatik, Mathematik oder ähnliche Studiengänge</li>
  <li>Interesse an Mensch-Roboter Interaktion und Roboterhänden</li>
  <li>(wünschenswert) Vorerfahrungen mit Machine Learning in Python</li>
</ul>
      </div>
    </div>
  </div>
</div>

<h3 id="vorhersage-von-leistungsfähigkeit-von-menschen-durch-gpt-modelle">Vorhersage von Leistungsfähigkeit von Menschen durch GPT Modelle</h3>

<div class="feature__wrapper">
  <div class="feature__item--left">
    <div class="archive__item">
      <div class="archive__item-teaser">
        
          <div style="position:relative">
            <img src="assets\mandischer\capability_gpt.png" />
            <span class="archive__item-caption">© Universität Augsburg</span>
          </div>
        
        
        <h4>Tags:</h4>
        <ul>
          
            
            
            
            
            
            
              <li>Masterarbeit</li>
            
            
          
        </ul>
        
        <a class="btn btn--primary" href="https://www.uni-augsburg.de/de/fakultaet/fai/informatik/prof/imech/team/nils-mandischer">Kontakt</a>
        
          <a class="btn btn--primary" href="assets\mandischer\capability_gpt.pdf">Zusätzliche Informationen</a>
        
      </div>
      <div class="archive__item-body">
        <p>Am Lehrstuhl für Mechatronik untersuchen wir Mensch-Roboter Interaktion von einem besonderen Blickwinkel. Jeder Mensch besitzt Fähigkeiten. Diese lassen sich bereits über arbeitsmedizinische Dokumentationsverfahren bewerten. Gleichsam lassen sich Anforderungen an einen Arbeitsprozess definieren. Über den Vergleich von Fähigkeiten und Anforderungen lässt sich dann auswerten, in welchen Bereichen eine Person eingesetzt werden kann. Das ist besonders dann wichtig, wenn es sich bei den Personen um Menschen mit Behinderung oder alternde Arbeitnehmer handelt, die eben nicht in beliebigen Arbeitsprozessen eingesetzt werden können.</p>

        <p>Um dieses Vorgehen in Mensch-Roboter-Systemen einsetzen zu können, muss der Roboter in die Lage versetzt werden, die Fähigkeiten des Menschen automatisch erfassen zu können. In dieser Arbeit soll untersucht werden, inwiefern Multimodale GPT Modelle (auch Vision Language Models genannt) verwendet werden können, um basierend auf Videodaten Vorhersagen über die Leistungsfähigkeit von Personen zu treffen. Dazu sollen verschiedene Ansätze verglichen und erweitert werden, um später Fragen bewerten zu können, wie „Kann die Person die Schraube greifen?“ oder „Kann die Person das Werkzeug bedienen?“.</p>

        <p><em>Deine Aufgaben</em></p>
        <ul>
  <li>Erstellen eines kleinen Datensatzes mit unserem Prüfstand</li>
  <li>Benchmark bestehender GPT Modelle im Hinblick auf die Vorhersagequalität der Leistungsfähigkeit von Menschen</li>
  <li>Einsatz von Prompt Engineering Techniken, sowie Erweiterung und Fein-Tuning der Modelle</li>
  <li>Anbindung der Methodik an unseren Prüfstand</li>
</ul>

        <p><em>Du bietest</em></p>
        <ul>
  <li>Studium der Ingenieursinformatik, Informatik, Medizininformatik, Mathematik oder ähnliche Studiengänge</li>
  <li>Interesse an Mensch-Roboter Teaming und Ergonomie</li>
  <li>Interesse an Maschinellem Lernen</li>
  <li>Gute Deutschkenntnisse in Wort und Schrift</li>
</ul>

        <p>Die Arbeit wird von mir zusammen mit Damian Boborzi betreut.</p>
      </div>
    </div>
  </div>
</div>

<h3 id="datengetriebene-model-predictive-control">Datengetriebene Model Predictive Control</h3>

<div class="feature__wrapper">
  <div class="feature__item--left">
    <div class="archive__item">
      <div class="archive__item-teaser">
        
        
        <h4>Tags:</h4>
        <ul>
          
            
            
            
            
            
            
            
          
            
            
            
            
            
            
              <li>Masterarbeit</li>
            
            
          
        </ul>
        
        <a class="btn btn--primary" href="https://www.uni-augsburg.de/de/fakultaet/fai/informatik/prof/imech/team/yi-zhang">Kontakt</a>
        
      </div>
      <div class="archive__item-body">
        <p>Du hast Kenntnisse in der Regelungstechnik und Interesse an der Integration von KI-Methoden in die Regelungs-/Steuerungsmethoden?</p>

        <p>Model Predictive Control ist eine Reglungstechnik, bei der ein System – wie z. B. ein Auto, eine Drohne oder eine Industrieanlage – in die Zukunft “blickt”, um zu entscheiden, was es als Nächstes tun soll. MPC nutzt ein Modell, um vorherzusagen, wie sich das System entwickeln wird. Es plant also im Voraus, indem es berechnet, welche Aktionen (wie Beschleunigen, Bremsen oder Lenken) am besten geeignet sind, um ein Ziel zu erreichen, ohne dabei Einschränkungen zu verletzen (wie z. B. eine maximale Geschwindigkeit oder bestimmte Sicherheitsgrenzen).</p>

        <p><em>Was wir bieten</em></p>
        <ul>
  <li>Einblicke in den Stand der Technik von probabilistischem Deep Learning</li>
  <li>Einführung von Jax</li>
  <li>Flexible Betreuung</li>
</ul>

        <p><em>Was du mitbringst</em></p>
        <ul>
  <li>Vorkenntnisse in Regelungstechnik, Deep Learning, Reinforcement Learning</li>
  <li>Programmierfähigkeit in Python</li>
</ul>
      </div>
    </div>
  </div>
</div>

<h3 id="weiterentwicklung-unserer-softwarepakete-für-graph-neural-networks">Weiterentwicklung unserer Softwarepakete für Graph Neural Networks</h3>

<div class="feature__wrapper">
  <div class="feature__item--left">
    <div class="archive__item">
      <div class="archive__item-teaser">
        
          <div style="position:relative">
            <img src="assets\trommer\mgn_logo.png" />
            <span class="archive__item-caption">© Universität Augsburg</span>
          </div>
        
        
        <h4>Tags:</h4>
        <ul>
          
            
            
            
            
              <li>Projektmodul</li>
            
            
            
            
          
            
            
            
            
            
              <li>Bachelorarbeit</li>
            
            
            
          
            
            
            
            
            
            
              <li>Masterarbeit</li>
            
            
          
            
            
            
            
            
            
            
              <li>Hiwi-Stelle</li>
            
          
        </ul>
        
        <a class="btn btn--primary" href="https://www.uni-augsburg.de/de/fakultaet/fai/informatik/prof/imech/team/julian-trommer">Kontakt</a>
        
          <a class="btn btn--primary" href="https://github.com/una-auxme/MeshGraphNets.jl">Zusätzliche Informationen</a>
        
      </div>
      <div class="archive__item-body">
        <p>Die Programmiersprache <a href="https://julialang.org/"><em>Julia</em></a> wächst aktuell stark in ihrer Anwendung sowohl in der Forschung als auch in der Industrie bei großen Unternehmen wie beispielsweise <a href="https://pretalx.com/juliacon2024/talk/DMLTLG/">ASML</a> und <a href="https://arxiv.org/abs/2403.11648">Bosch</a>. Dabei arbeitet unser Lehrstuhl aktiv an der (Weiter-)entwicklung unser aktuellen <a href="https://github.com/una-auxme/">Softwarepakete</a> für <em>Julia</em>, besonders im Bereich Graph Neural Networks. Dabei gibt es immer aktuelle Themen die in Angriff genommen werden können um das Paket und die Sprache voranzutreiben.</p>

        <p>Dies beinhaltet:</p>

        <ul>
  <li>Entwicklung neuer Funktionen der Pakete</li>
  <li>Mitwirken an <strong><em>Core</em></strong>-Paketen von <em>Julia</em></li>
  <li>Instandhaltung der aktuellen Software</li>
</ul>
      </div>
    </div>
  </div>
</div>

<h3 id="datengetriebene-beobachter">Datengetriebene Beobachter</h3>

<div class="feature__wrapper">
  <div class="feature__item--left">
    <div class="archive__item">
      <div class="archive__item-teaser">
        
        
        <h4>Tags:</h4>
        <ul>
          
            
            
            
            
            
            
            
          
            
            
            
            
            
            
              <li>Masterarbeit</li>
            
            
          
        </ul>
        
        <a class="btn btn--primary" href="https://www.uni-augsburg.de/de/fakultaet/fai/informatik/prof/imech/team/yi-zhang">Kontakt</a>
        
      </div>
      <div class="archive__item-body">
        <p>Du hast Kenntnisse in der Regelungstechnik und Interesse an der Integration von KI-Methoden in die Regelungs-/Steuerungsmethoden?</p>

        <p>In der Regelungstechnik ist ein Beobachter ein System, das aus bekannten Eingangsgrößen (z.B. Stellgrößen oder messbaren Störgrößen) und Ausgangsgrößen (Messgrößen) eines beobachteten Bezugssystems nicht messbare Größen (Zustände) rekonstruiert.  Für nichtlineare Systeme mit teilweiser unbekannter Dynamik sind traditionelle Beobachter nur bedingt einsetzbar. Unser Ziel ist es, einen datengesteuerten Beobachter zu entwerfen, der nicht messbare Zustände aus Systemeingaben und -ausgaben lernen kann.</p>

        <p><em>Was wir bieten</em></p>
        <ul>
  <li>Einblicke in den Stand der Technik von probabilistischem Deep Learning</li>
  <li>Einführung von Jax</li>
  <li>Flexible Betreuung</li>
</ul>

        <p><em>Was du mitbringst</em></p>
        <ul>
  <li>Vorkenntnisse in Regelungstechnik, Deep Learning</li>
  <li>Programmierfähigkeit in Python</li>
</ul>
      </div>
    </div>
  </div>
</div>

<h3 id="fine-tuning-von-large-reconstruction-models-für-die-3d-objektgenerierung">Fine-tuning von Large Reconstruction Models für die 3D Objektgenerierung</h3>

<div class="feature__wrapper">
  <div class="feature__item--left">
    <div class="archive__item">
      <div class="archive__item-teaser">
        
          <div style="position:relative">
            <img src="assets\boborzi\instantmesh.png" />
            <span class="archive__item-caption">TencentARC</span>
          </div>
        
        
        <h4>Tags:</h4>
        <ul>
          
            
            
            
            
              <li>Projektmodul</li>
            
            
            
            
          
            
            
            
            
            
            
              <li>Masterarbeit</li>
            
            
          
        </ul>
        
        <a class="btn btn--primary" href="https://www.uni-augsburg.de/de/fakultaet/fai/informatik/prof/imech/team/damian-boborzi">Kontakt</a>
        
      </div>
      <div class="archive__item-body">
        <p>Kann man per Knopfdruck 3D-Objekte erzeugen? Generative Modelle wie Stable Diffusion oder DALL-E können bereits beeindruckende Bilder anhand einer Beschreibung auf Knopfdruck erzeugen. Das wäre auch für 3D-Objekte interessant, und tatsächlich lassen sich Methoden der Bildgenerierung auch zur Erzeugung von 3D-Objekten nutzen. Allerdings sind die Ergebnisse oft noch nicht so überzeugend wie im Bildbereich und haben häufig eine lange Rechenzeit.</p>

        <p>Large Reconstruction Models (zum Beispiel <a href="https://huggingface.co/spaces/TencentARC/InstantMesh">InstantMesh</a>) sollen vor allem das Problem der langen Rechenzeit lösen, indem ein großes Transformermodell darauf trainiert wird, in einem Durchgang direkt ein 3D-Modell zu erzeugen.</p>

        <p>Aus dem Bildbereich kennt man verschiedene Methoden, um große generative Modelle durch Fine-Tuning anzupassen, um einen bestimmten Stil oder eine bestimmte Art von Bildern zu erzeugen. Ähnlich soll in dieser Arbeit untersucht werden, wie ein Large Reconstruction Model mithilfe von Fine-Tuning angepasst werden könnte, um Objekte aus einer bestimmten Domäne, wie beispielsweise Fahrzeuge, besser generieren zu können.</p>
      </div>
    </div>
  </div>
</div>

<h3 id="konditionierung-von-diffusion-modellen">Konditionierung von Diffusion Modellen</h3>

<div class="feature__wrapper">
  <div class="feature__item--left">
    <div class="archive__item">
      <div class="archive__item-teaser">
        
          <div style="position:relative">
            <img src="assets\boborzi\diffusion.png" />
            <span class="archive__item-caption">© Universität Augsburg</span>
          </div>
        
        
        <h4>Tags:</h4>
        <ul>
          
            
            
            
            
              <li>Projektmodul</li>
            
            
            
            
          
            
            
            
            
            
            
              <li>Masterarbeit</li>
            
            
          
        </ul>
        
        <a class="btn btn--primary" href="https://www.uni-augsburg.de/de/fakultaet/fai/informatik/prof/imech/team/damian-boborzi">Kontakt</a>
        
      </div>
      <div class="archive__item-body">
        <p>Du findest generative Modelle wie Stable Diffusion oder DALL-E, die anhand von Text detailreiche Bilder erzeugen können, spannend und hast Interesse, dich in aktuelle Machine-Learning-Themen einzuarbeiten?</p>

        <p>In dieser Arbeit hast du die Möglichkeit, Methoden wie <a href="https://github.com/CompVis/stable-diffusion">Stable Diffusion</a> und <a href="https://stability.ai/news/introducing-stable-video-3d">SV3D</a> genauer kennenzulernen. Stable Diffusion ermöglicht es, Bilder anhand von Text oder anderen Vorgaben zu erzeugen. Bei der Methode SV3D wird ein Bild als Vorgabe verwendet, um mehrere Bilder zu generieren, die das Objekt aus verschiedenen Perspektiven zeigen. Mithilfe dieser Perspektiven können anschließend 3D-Objekte erzeugt werden. In der Arbeit sollen Möglichkeiten untersucht werden, wie Diffsuion Modelle auf andere Eingaben, wie zum Beispiel Zeichnungen, konditioniert werden können und wie sich diese Eingaben auf die Generierung auswirken. Abhängig von der Art der Arbeit können verschiedene Ansätze untersucht werden.</p>
      </div>
    </div>
  </div>
</div>


        
      </section>

      <footer class="page__meta">
        
        


        

      </footer>

      

      
    </div>

    
  </article>

  
  
</div>

      
    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      
      
        
          
          
            <li><a href="https://github.com/una-auxme" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
          
        
      
        
          
          
        
      
        
          
          
        
      

      
      
      
        
      
        
      
        
      
        
      
        
          
          
      
        <li><a href="/impressum/" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-file"></i> Impressum</a></li>
      
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2025 Lehrstuhl für Mechatronik. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>









  </body>
</html>
